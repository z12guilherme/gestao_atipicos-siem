    <div align="center">

# ğŸ›¡ï¸ SIEM com Elastic Stack para Logs da Vercel ğŸ›¡ï¸

**Um sistema simplificado de SIEM (Security Information and Event Management) para monitorar a seguranÃ§a e o desempenho de aplicaÃ§Ãµes Vercel em tempo real.**

</div>

![Elastic Stack](https://img.shields.io/badge/Elastic%20Stack-8.11.3-005571?logo=elastic-stack&style=for-the-badge)
![Docker](https://img.shields.io/badge/Docker-20.10-2496ED?logo=docker&style=for-the-badge)
![Vercel](https://img.shields.io/badge/Vercel-Log%20Drains-black?logo=vercel&style=for-the-badge)

Este projeto utiliza o **Elastic Stack** (Elasticsearch, Logstash e Kibana) para coletar, processar, armazenar e visualizar logs de aplicaÃ§Ãµes hospedadas na Vercel, criando um dashboard centralizado para monitoramento de eventos, identificaÃ§Ã£o de padrÃµes e anÃ¡lise de seguranÃ§a.

---

## âœ¨ Principais Funcionalidades

*   **Coleta em Tempo Real**: Recebe logs da Vercel via Log Drains.
*   **Processamento e Enriquecimento**: O pipeline do Logstash faz o parsing dos logs, extrai o IP do cliente, enriquece os dados com geolocalizaÃ§Ã£o (paÃ­s, cidade, coordenadas) e corrige o timestamp.
*   **Armazenamento Centralizado**: Utiliza o Elasticsearch para armazenar e indexar os logs de forma eficiente.
*   **VisualizaÃ§Ã£o Interativa**: Permite a criaÃ§Ã£o de dashboards e visualizaÃ§Ãµes dinÃ¢micas no Kibana para anÃ¡lise de seguranÃ§a e performance.
*   **Ambiente Containerizado**: Todo o stack Ã© orquestrado com Docker Compose, facilitando a configuraÃ§Ã£o e a execuÃ§Ã£o.

## ğŸ—ï¸ Arquitetura

O fluxo de dados foi desenhado para ser simples e eficiente:

```mermaid
graph TD
    A[Vercel] -- Log Drains (HTTP POST) --> B(TÃºnel PÃºblico);
    subgraph "Ambiente Local (Docker)"
        B(TÃºnel PÃºblico) -- ngrok ou Cloudflare --> C[Logstash];
        C -- Processa e Enriquece --> D[Elasticsearch];
        E[Kibana] -- Consulta e Visualiza --> D;
    end
    style A fill:#000,color:#fff,stroke:#fff,stroke-width:2px
    style C fill:#E67E22,color:#fff,stroke:#fff,stroke-width:2px
    style D fill:#005571,color:#fff,stroke:#fff,stroke-width:2px
    style E fill:#005571,color:#fff,stroke:#fff,stroke-width:2px
```

1.  **Vercel**: Gera logs de acesso e de funÃ§Ãµes para uma aplicaÃ§Ã£o.
2.  **Log Drains**: A Vercel envia esses logs em tempo real via HTTP POST para uma URL pÃºblica.
3.  **TÃºnel (ngrok/Cloudflare)**: Uma ferramenta de tÃºnel expÃµe o serviÃ§o Logstash local para a internet, fornecendo a URL pÃºblica necessÃ¡ria.
4.  **Logstash**: Recebe os logs brutos, os processa e os envia para o Elasticsearch.
5.  **Elasticsearch**: Armazena e indexa os logs para busca e anÃ¡lise.
6.  **Kibana**: Conecta-se ao Elasticsearch para exploraÃ§Ã£o dos dados e criaÃ§Ã£o de dashboards.

## ğŸš€ Como ComeÃ§ar

### ğŸ“‹ PrÃ©-requisitos

*   Docker e Docker Compose instalados.
*   Uma conta na Vercel com um projeto ativo.
*   Uma ferramenta de tÃºnel como ngrok ou Cloudflare Tunnel.

### âš™ï¸ ConfiguraÃ§Ã£o e ExecuÃ§Ã£o

1.  **Clone o RepositÃ³rio**
    ```bash
    git clone gestao_atipicos-siem
    cd gestao_atipicos-siem
    ```

2.  **Exponha o Logstash**
    O Logstash irÃ¡ escutar na porta `8080`. Exponha essa porta para a internet usando sua ferramenta de tÃºnel preferida.
    ```bash
    # Exemplo com Cloudflare Tunnel (recomendado pelo MANUAL.md)
    cloudflared tunnel --url http://localhost:8080
    ```
    Copie a URL `https` fornecida pela ferramenta (ex: `https://random-words.trycloudflare.com`).

3.  **Configure o Vercel Log Drains**
    No dashboard do seu projeto na Vercel, vÃ¡ para **Settings > Log Drains**, selecione o formato **JSON** e cole a URL obtida no passo anterior.

4.  **Inicie o Elastic Stack**
    Com o Docker em execuÃ§Ã£o, suba os contÃªineres:
    ```bash
    docker-compose up -d
    ```

5.  **Acesse o Kibana**
    Abra o navegador e acesse `http://localhost:5601`. Pode levar alguns minutos para o Kibana estar totalmente operacional.

## ğŸ”§ Pipeline do Logstash

O arquivo de configuraÃ§Ã£o `logstash/pipeline/vercel.conf` define o pipeline de processamento:

*   **Input**: Recebe logs via HTTP na porta `8080`.
*   **Filtros**:
    *   Extrai o endereÃ§o de IP do cliente (`[proxy][clientIp]`).
    *   Utiliza o filtro `geoip` para enriquecer o log com dados de geolocalizaÃ§Ã£o.
    *   Converte o timestamp da Vercel (em milissegundos) para o formato de data padrÃ£o do Elastic.
*   **Output**: Envia os dados processados para um Ã­ndice diÃ¡rio no Elasticsearch (`vercel-gemini-%{+YYYY.MM.dd}`).

## ğŸ“Š Visualizando os Dados

ApÃ³s a ingestÃ£o dos primeiros logs, siga estes passos no Kibana:

1.  VÃ¡ para **Management > Stack Management > Index Management** para verificar se o Ã­ndice (`gestao_atipicos_logs-...`) foi criado.
2.  VÃ¡ para **Analytics > Discover**. Crie um "Data View" usando o padrÃ£o de Ã­ndice `gestao_atipicos_logs-*`.
3.  Comece a explorar seus logs e a criar visualizaÃ§Ãµes para o seu dashboard!

---

Para um guia mais detalhado sobre a configuraÃ§Ã£o de cada componente, consulte o arquivo **MANUAL.md**.