<div align="center">

# üõ°Ô∏è SIEM com Elastic Stack para Logs da Vercel üõ°Ô∏è

**Um sistema simplificado de SIEM (Security Information and Event Management) para monitorar a seguran√ßa e o desempenho de aplica√ß√µes Vercel em tempo real.**

</div>

![Elastic Stack](https://img.shields.io/badge/Elastic%20Stack-8.11.3-005571?logo=elastic-stack&style=for-the-badge)
![Docker](https://img.shields.io/badge/Docker-20.10-2496ED?logo=docker&style=for-the-badge)
![Vercel](https://img.shields.io/badge/Vercel-Log%20Drains-black?logo=vercel&style=for-the-badge)

Este projeto utiliza o **Elastic Stack** (Elasticsearch, Logstash e Kibana) para coletar, processar, armazenar e visualizar logs de aplica√ß√µes hospedadas na Vercel, criando um dashboard centralizado para monitoramento de eventos, identifica√ß√£o de padr√µes e an√°lise de seguran√ßa.

---

## ‚ú® Principais Funcionalidades

*   **Coleta em Tempo Real**: Recebe logs da Vercel via Log Drains.
*   **Processamento e Enriquecimento**: O pipeline do Logstash faz o parsing dos logs, extrai o IP do cliente, enriquece os dados com geolocaliza√ß√£o (pa√≠s, cidade, coordenadas) e corrige o timestamp.
*   **Armazenamento Centralizado**: Utiliza o Elasticsearch para armazenar e indexar os logs de forma eficiente.
*   **Visualiza√ß√£o Interativa**: Permite a cria√ß√£o de dashboards e visualiza√ß√µes din√¢micas no Kibana para an√°lise de seguran√ßa e performance.
*   **Ambiente Containerizado**: Todo o stack √© orquestrado com Docker Compose, facilitando a configura√ß√£o e a execu√ß√£o.

## üèóÔ∏è Arquitetura

O fluxo de dados foi desenhado para ser simples e eficiente:

```mermaid
graph TD
    A[Vercel] -- Log Drains (HTTP POST) --> B(T√∫nel P√∫blico);
    subgraph "Ambiente Local (Docker)"
        B(T√∫nel P√∫blico) -- ngrok ou Cloudflare --> C[Logstash];
        C -- Processa e Enriquece --> D[Elasticsearch];
        E[Kibana] -- Consulta e Visualiza --> D;
    end
    style A fill:#000,color:#fff,stroke:#fff,stroke-width:2px
    style C fill:#E67E22,color:#fff,stroke:#fff,stroke-width:2px
    style D fill:#005571,color:#fff,stroke:#fff,stroke-width:2px
    style E fill:#005571,color:#fff,stroke:#fff,stroke-width:2px
```

1.  **Vercel**: Gera logs de acesso e de fun√ß√µes para uma aplica√ß√£o.
2.  **Log Drains**: A Vercel envia esses logs em tempo real via HTTP POST para uma URL p√∫blica.
3.  **T√∫nel (ngrok/Cloudflare)**: Uma ferramenta de t√∫nel exp√µe o servi√ßo Logstash local para a internet, fornecendo a URL p√∫blica necess√°ria.
4.  **Logstash**: Recebe os logs brutos, os processa e os envia para o Elasticsearch.
5.  **Elasticsearch**: Armazena e indexa os logs para busca e an√°lise.
6.  **Kibana**: Conecta-se ao Elasticsearch para explora√ß√£o dos dados e cria√ß√£o de dashboards.

## üöÄ Como Come√ßar

### üìã Pr√©-requisitos

*   Docker e Docker Compose instalados.
*   Uma conta na Vercel com um projeto ativo.
*   Uma ferramenta de t√∫nel como ngrok ou Cloudflare Tunnel.

### ‚öôÔ∏è Configura√ß√£o e Execu√ß√£o

1.  **Clone o Reposit√≥rio**
    ```bash
    git clone <URL_DO_SEU_REPOSITORIO>
    cd <NOME_DA_PASTA>
    ```

2.  **Exponha o Logstash**
    O Logstash ir√° escutar na porta `8080`. Exponha essa porta para a internet usando sua ferramenta de t√∫nel preferida.
    ```bash
    # Exemplo com Cloudflare Tunnel (recomendado pelo MANUAL.md)
    cloudflared tunnel --url http://localhost:8080
    ```
    Copie a URL `https` fornecida pela ferramenta (ex: `https://random-words.trycloudflare.com`).

3.  **Configure o Vercel Log Drains**
    No dashboard do seu projeto na Vercel, v√° para **Settings > Log Drains**, selecione o formato **JSON** e cole a URL obtida no passo anterior.

4.  **Inicie o Elastic Stack**
    Com o Docker em execu√ß√£o, suba os cont√™ineres:
    ```bash
    docker-compose up -d
    ```

5.  **Acesse o Kibana**
    Abra o navegador e acesse `http://localhost:5601`. Pode levar alguns minutos para o Kibana estar totalmente operacional.

## üîß Pipeline do Logstash

O arquivo de configura√ß√£o `logstash/pipeline/vercel.conf` define o pipeline de processamento:

*   **Input**: Recebe logs via HTTP na porta `8080`.
*   **Filtros**:
    *   Extrai o endere√ßo de IP do cliente (`[proxy][clientIp]`).
    *   Utiliza o filtro `geoip` para enriquecer o log com dados de geolocaliza√ß√£o.
    *   Converte o timestamp da Vercel (em milissegundos) para o formato de data padr√£o do Elastic.
*   **Output**: Envia os dados processados para um √≠ndice di√°rio no Elasticsearch (`vercel-gemini-%{+YYYY.MM.dd}`).

## üìä Visualizando os Dados

Ap√≥s a ingest√£o dos primeiros logs, siga estes passos no Kibana:

1.  V√° para **Management > Stack Management > Index Management** para verificar se o √≠ndice (`gestao_atipicos_logs-...`) foi criado.
2.  V√° para **Analytics > Discover**. Crie um "Data View" usando o padr√£o de √≠ndice `gestao_atipicos_logs-*`.
3.  Comece a explorar seus logs e a criar visualiza√ß√µes para o seu dashboard!

---

Para um guia mais detalhado sobre a configura√ß√£o de cada componente, consulte o arquivo **MANUAL.md**.